{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4ae7b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98f8aefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import math\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mostCommon import most_common\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten,MaxPooling2D,Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import (\n",
    "    EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    ")\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3adf23b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "    # plot loss\n",
    "    pyplot.subplot(211)\n",
    "    pyplot.title('Cross Entropy Loss')\n",
    "    pyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "    pyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "    # plot accuracy\n",
    "    pyplot.subplot(212)\n",
    "    pyplot.title('Classification Accuracy')\n",
    "    pyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
    "    pyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
    "    # save plot to file\n",
    "    filename = sys.argv[0].split('/')[-1]\n",
    "    pyplot.savefig('' + '_plot.png')\n",
    "    pyplot.close()\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    # prepare pixel data\n",
    "    trainX, testX = prep_pixels(trainX, testX)\n",
    "    # define model\n",
    "    model = define_model()\n",
    "    # fit model\n",
    "    history = model.fit(trainX, trainY, epochs=100, batch_size=64, validation_data=(testX, testY), verbose=0)\n",
    "    # evaluate model\n",
    "    _, acc = model.evaluate(testX, testY, verbose=0)\n",
    "    print('> %.3f' % (acc * 100.0))\n",
    "    # learning curves\n",
    "    summarize_diagnostics(history)\n",
    "\n",
    "def makeModel():\n",
    "    drop=0.01\n",
    "    kernel=(2,2)\n",
    "    LR=1e-3\n",
    "    opt = Adam(learning_rate=LR, decay=LR / 20)\n",
    "    # Create model\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(16, kernel_size=kernel, activation='relu', \n",
    "                     kernel_initializer='he_uniform', padding='same', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, 3)))\n",
    "\n",
    "    model.add(Conv2D(16, kernel_size=kernel, activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(drop))\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=kernel, activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(32, kernel_size=kernel, activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(drop))\n",
    "\n",
    "    model.add(Conv2D(64, kernel_size=kernel, activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(64, kernel_size=kernel, activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(drop))\n",
    "\n",
    "    model.add(Conv2D(126, kernel_size=kernel, activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(126, kernel_size=kernel, activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(drop))\n",
    "\n",
    "    model.add(Conv2D(256, kernel_size=kernel, activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(256, kernel_size=kernel, activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(drop))\n",
    "    \n",
    "    #Flatten results\n",
    "    model.add(Flatten())\n",
    "\n",
    "    #Hidden layers of 512 neurons\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6c5fff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_WIDTH=256\n",
    "IMAGE_HEIGHT=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23a362de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load all patients \n",
    "my_data = pd.read_csv('../data/Five_Frames_Per_patient.csv')\n",
    "patients_data=pd.read_csv('../data/videos_data.csv')\n",
    "data_array = my_data.to_numpy()\n",
    "patients_array=patients_data[\"FileName\"].to_numpy()\n",
    "images_path = '../data/Five_Frames_Per_patient/'\n",
    "no_of_test_patients=math.floor(patients_array.size*0.2) \n",
    "images_data = []\n",
    "models = []\n",
    "\n",
    "df=my_data\n",
    "data_array=df.to_numpy()\n",
    "for i in data_array:\n",
    "    img = cv2.imread(images_path + i[0] + '.' + i[2])\n",
    "    img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "    img_2d = img.reshape(IMAGE_WIDTH ,IMAGE_HEIGHT,3)\n",
    "    images_data.append(img_2d)\n",
    "\n",
    "X=np.asarray(images_data)\n",
    "y = np.asarray(my_data['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2694b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label encode classes to numbers\n",
    "number = preprocessing.LabelEncoder()\n",
    "y=number.fit_transform(y)\n",
    "#One-hot Encode y\n",
    "y=to_categorical(y,3)\n",
    "\n",
    "# Scale the pixels\n",
    "X=X/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6164c2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the training data augmentation object\n",
    "MODEL_PATH=os.path.join('', \"Conv2d-Better\")\n",
    "\n",
    "\n",
    "\n",
    "mcp_save = ModelCheckpoint(\n",
    "    MODEL_PATH,\n",
    "    save_best_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7198b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=16\n",
    "EPOCHS=20\n",
    "LR=0.2\n",
    "\n",
    "# Define callbacks\n",
    "earlyStopping = EarlyStopping(\n",
    "    monitor='loss',\n",
    "    patience=20,\n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "\n",
    "reduce_lr_loss = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.7,\n",
    "    patience=7,\n",
    "    verbose=1,\n",
    "    min_delta=1e-4,\n",
    "    mode='min'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fe37205",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Patient 0 ------------------------------ \n",
      "\n",
      "Indexes: [0, 1, 2, 3, 4]\n",
      "Training Model...\n",
      "Epoch 1/10\n",
      "37/37 [==============================] - 15s 255ms/step - loss: 1.4655 - accuracy: 0.5212\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - 10s 257ms/step - loss: 0.7350 - accuracy: 0.6995\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - 9s 234ms/step - loss: 0.6453 - accuracy: 0.7504\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - 14s 389ms/step - loss: 0.5772 - accuracy: 0.7606\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - 9s 235ms/step - loss: 0.4969 - accuracy: 0.7912\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - 9s 235ms/step - loss: 0.4578 - accuracy: 0.8132\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - 9s 231ms/step - loss: 0.5141 - accuracy: 0.7956\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - 9s 249ms/step - loss: 0.4115 - accuracy: 0.8421\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - 9s 236ms/step - loss: 0.4493 - accuracy: 0.8098\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - 11s 290ms/step - loss: 0.4216 - accuracy: 0.8421\n",
      "getting predictions of each model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RS3\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-431d9c5bf49a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0mframe_predictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m     \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "l=5\n",
    "ll=[-5,-4,-3,-2,-1]\n",
    "patients_predictions=[]\n",
    "patients_actual=[]\n",
    "\n",
    "frame_predictions=[]\n",
    "o=19\n",
    "for o in range(122):\n",
    "    print('---------------------------- Patient ' + str(o) + ' ------------------------------ \\n')\n",
    "    \n",
    "    trainAug = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    fill_mode='nearest',\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    "    )\n",
    "    ll=[t+l for t in ll]\n",
    "    print('Indexes: '+str(ll))\n",
    "    X_test=[]\n",
    "    y_test=[]\n",
    "    X_train=[]\n",
    "    y_train=[]\n",
    "    X_test=np.take(X,ll,axis=0)\n",
    "    y_test=np.take(y,ll,axis=0)\n",
    "    X_train=np.delete(X,ll,axis=0)\n",
    "    y_train=np.delete(y,ll,axis=0)\n",
    "    \n",
    "\n",
    "    # Creating array test splits for models\n",
    "    model=makeModel()\n",
    "    \n",
    "    \n",
    "    print('Training Model...')\n",
    "    history=model.fit(\n",
    "    trainAug.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "    steps_per_epoch=len(X_train) // BATCH_SIZE,\n",
    "    epochs=10\n",
    "    )\n",
    "    \n",
    "    \n",
    "\n",
    "    print('getting predictions of each model...')\n",
    "    prediction=model.predict_classes(X_test)\n",
    "    patients_predictions.append(most_common(prediction.tolist()))\n",
    "    patients_actual.append(np.argmax(y_test[0]))\n",
    "    \n",
    "    for i in prediction:\n",
    "        frame_predictions.append(i)\n",
    "    keras.backend.clear_session()\n",
    "    \n",
    "    \n",
    "    \n",
    "print('All Done :)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ee9d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "_, train_acc = model.evaluate(X_train, y_train, verbose=0)\n",
    "_, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'],\n",
    "           loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55069768",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Patient Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab07701",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frames Confusion Matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
