{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4ae7b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98f8aefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import math\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten,MaxPooling2D,Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import (\n",
    "    EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from mostCommon import most_common,patient_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6c5fff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_WIDTH=224\n",
    "IMAGE_HEIGHT=224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23a362de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'regular': 280, 'pneumonia': 180, 'covid': 150})\n"
     ]
    }
   ],
   "source": [
    "#Load all patients \n",
    "my_data = pd.read_csv('../data/Five_Frames_Per_patient.csv')\n",
    "patients_data=pd.read_csv('../data/videos_data.csv')\n",
    "data_array = my_data.to_numpy()\n",
    "patients_array=patients_data[\"FileName\"].to_numpy()\n",
    "images_path = '../data/Five_Frames_Per_patient/'\n",
    "no_of_test_patients=math.floor(patients_array.size*0.2) \n",
    "images_data = []\n",
    "models = []\n",
    "\n",
    "df=my_data\n",
    "data_array=df.to_numpy()\n",
    "for i in data_array:\n",
    "    img = cv2.imread(images_path + i[0] + '.' + i[2], cv2.IMREAD_GRAYSCALE)\n",
    "    img=  cv2.equalizeHist(img)\n",
    "    img = cv2.resize(img, (IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "    img_2d = img.reshape(IMAGE_WIDTH ,IMAGE_HEIGHT,1)\n",
    "    images_data.append(img_2d)\n",
    "\n",
    "X=np.asarray(images_data)\n",
    "y = np.asarray(my_data['Label'])\n",
    "print(Counter(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18a3f119",
   "metadata": {},
   "outputs": [],
   "source": [
    "testPatient_indexes= [1,2,12,14,15,22,\n",
    "                      33,34,37,42,43,52,53,\n",
    "                      92,95,96,99,101,102,104,107,110,115,118]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d960910",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting frame indexes of each patient\n",
    "frames_index=[]\n",
    "for i in testPatient_indexes:\n",
    "  j=i*5\n",
    "  z=j+5\n",
    "  while j<z:\n",
    "    frames_index.append(j)\n",
    "    j+=1\n",
    "\n",
    "# Adding the frames to X_test\n",
    "X_test=np.take(X,frames_index,axis=0)\n",
    "y_test=np.take(y,frames_index,axis=0)\n",
    "# Removing the frames from X_train\n",
    "X_train=np.delete(X,frames_index,axis=0)\n",
    "y_train=np.delete(y,frames_index,axis=0)\n",
    "\n",
    "# Scale the pixels\n",
    "X_train=X_train/255.0\n",
    "X_test=X_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4752071b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'covid': 225, 'pneumonia': 225, 'regular': 225})\n"
     ]
    }
   ],
   "source": [
    "#Applying SMOTE\n",
    "oversample = SMOTE()\n",
    "X_train=np.resize(X_train,(X_train.shape[0],50176))\n",
    "X_train,y_train=oversample.fit_resample(X_train, y_train)\n",
    "counter=Counter(y_train)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33a15d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (675, 50176)\n",
      "y_train: (675,)\n",
      "X_test: (120, 224, 224, 1)\n",
      "y_test: (120,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train: '+str(X_train.shape))\n",
    "print('y_train: '+str(y_train.shape))\n",
    "print('X_test: '+ str(X_test.shape))\n",
    "print('y_test: '+ str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d98cc369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=10000, random_state=42)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=LogisticRegression(random_state=42,solver='lbfgs',max_iter=10000)\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf01ec65",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=np.resize(X_test,(X_test.shape[0],50176))\n",
    "y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fe37205",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21  0  9]\n",
      " [ 0 24 11]\n",
      " [ 0  5 50]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       covid      1.000     0.700     0.824        30\n",
      "   pneumonia      0.828     0.686     0.750        35\n",
      "     regular      0.714     0.909     0.800        55\n",
      "\n",
      "    accuracy                          0.792       120\n",
      "   macro avg      0.847     0.765     0.791       120\n",
      "weighted avg      0.819     0.792     0.791       120\n",
      "\n",
      "[[ 4  0  2]\n",
      " [ 0  5  2]\n",
      " [ 0  1 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       covid      1.000     0.667     0.800         6\n",
      "   pneumonia      0.833     0.714     0.769         7\n",
      "     regular      0.714     0.909     0.800        11\n",
      "\n",
      "    accuracy                          0.792        24\n",
      "   macro avg      0.849     0.763     0.790        24\n",
      "weighted avg      0.820     0.792     0.791        24\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred, digits=3))\n",
    "patient_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39c281f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.87 accuracy with a standard deviation of 0.08\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores=cross_val_score(model, X_train, y_train, cv=5)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15aec607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'regular': 280, 'pneumonia': 180, 'covid': 150})\n",
      "X_train: (490, 50176)\n",
      "y_train: (490,)\n",
      "X_test: (120, 224, 224, 1)\n",
      "y_test: (120,)\n",
      "[[21  0  9]\n",
      " [ 0 22 13]\n",
      " [ 0  5 50]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       covid      1.000     0.700     0.824        30\n",
      "   pneumonia      0.815     0.629     0.710        35\n",
      "     regular      0.694     0.909     0.787        55\n",
      "\n",
      "    accuracy                          0.775       120\n",
      "   macro avg      0.836     0.746     0.774       120\n",
      "weighted avg      0.806     0.775     0.774       120\n",
      "\n",
      "[[ 4  0  2]\n",
      " [ 0  5  2]\n",
      " [ 0  1 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       covid      1.000     0.667     0.800         6\n",
      "   pneumonia      0.833     0.714     0.769         7\n",
      "     regular      0.714     0.909     0.800        11\n",
      "\n",
      "    accuracy                          0.792        24\n",
      "   macro avg      0.849     0.763     0.790        24\n",
      "weighted avg      0.820     0.792     0.791        24\n",
      "\n",
      "0.64 accuracy with a standard deviation of 0.07\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "IMAGE_WIDTH=224\n",
    "IMAGE_HEIGHT=224\n",
    "#Load all patients \n",
    "my_data = pd.read_csv('../data/Five_Frames_Per_patient.csv')\n",
    "patients_data=pd.read_csv('../data/videos_data.csv')\n",
    "data_array = my_data.to_numpy()\n",
    "patients_array=patients_data[\"FileName\"].to_numpy()\n",
    "images_path = '../data/Five_Frames_Per_patient/'\n",
    "no_of_test_patients=math.floor(patients_array.size*0.2) \n",
    "images_data = []\n",
    "models = []\n",
    "\n",
    "df=my_data\n",
    "data_array=df.to_numpy()\n",
    "for i in data_array:\n",
    "    img = cv2.imread(images_path + i[0] + '.' + i[2], cv2.IMREAD_GRAYSCALE)\n",
    "    img=  cv2.equalizeHist(img)\n",
    "    img = cv2.resize(img, (IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "    img_2d = img.reshape(IMAGE_WIDTH ,IMAGE_HEIGHT,1)\n",
    "    images_data.append(img_2d)\n",
    "\n",
    "X=np.asarray(images_data)\n",
    "y = np.asarray(my_data['Label'])\n",
    "print(Counter(y))\n",
    "\n",
    "testPatient_indexes= [1,2,12,14,15,22,\n",
    "                      33,34,37,42,43,52,53,\n",
    "                      92,95,96,99,101,102,104,107,110,115,118]\n",
    "#getting frame indexes of each patient\n",
    "frames_index=[]\n",
    "for i in testPatient_indexes:\n",
    "  j=i*5\n",
    "  z=j+5\n",
    "  while j<z:\n",
    "    frames_index.append(j)\n",
    "    j+=1\n",
    "\n",
    "# Adding the frames to X_test\n",
    "X_test=np.take(X,frames_index,axis=0)\n",
    "y_test=np.take(y,frames_index,axis=0)\n",
    "# Removing the frames from X_train\n",
    "X_train=np.delete(X,frames_index,axis=0)\n",
    "y_train=np.delete(y,frames_index,axis=0)\n",
    "\n",
    "# Scale the pixels\n",
    "X_train=X_train/255.0\n",
    "X_test=X_test/255.0\n",
    "X_train=np.resize(X_train,(X_train.shape[0],50176))\n",
    "print('X_train: '+str(X_train.shape))\n",
    "print('y_train: '+str(y_train.shape))\n",
    "print('X_test: '+ str(X_test.shape))\n",
    "print('y_test: '+ str(y_test.shape))\n",
    "model=LogisticRegression(random_state=42,solver='lbfgs',max_iter=10000)\n",
    "model.fit(X_train,y_train)\n",
    "X_test=np.resize(X_test,(X_test.shape[0],50176))\n",
    "y_pred=model.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred, digits=3))\n",
    "patient_score(y_test,y_pred)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores=cross_val_score(model, X_train, y_train, cv=5)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b8182df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'regular': 280, 'pneumonia': 180, 'covid': 150})\n",
      "X_train: (490, 99)\n",
      "y_train: (490,)\n",
      "X_test: (120, 99)\n",
      "y_test: (120,)\n",
      "[[19  2  9]\n",
      " [ 0 18 17]\n",
      " [ 0  3 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       covid      1.000     0.633     0.776        30\n",
      "   pneumonia      0.783     0.514     0.621        35\n",
      "     regular      0.667     0.945     0.782        55\n",
      "\n",
      "    accuracy                          0.742       120\n",
      "   macro avg      0.816     0.698     0.726       120\n",
      "weighted avg      0.784     0.742     0.733       120\n",
      "\n",
      "[[ 4  0  2]\n",
      " [ 0  4  3]\n",
      " [ 0  0 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       covid      1.000     0.667     0.800         6\n",
      "   pneumonia      1.000     0.571     0.727         7\n",
      "     regular      0.688     1.000     0.815        11\n",
      "\n",
      "    accuracy                          0.792        24\n",
      "   macro avg      0.896     0.746     0.781        24\n",
      "weighted avg      0.857     0.792     0.786        24\n",
      "\n",
      "0.63 accuracy with a standard deviation of 0.11\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "IMAGE_WIDTH=224\n",
    "IMAGE_HEIGHT=224\n",
    "#Load all patients \n",
    "my_data = pd.read_csv('../data/Five_Frames_Per_patient.csv')\n",
    "patients_data=pd.read_csv('../data/videos_data.csv')\n",
    "data_array = my_data.to_numpy()\n",
    "patients_array=patients_data[\"FileName\"].to_numpy()\n",
    "images_path = '../data/Five_Frames_Per_patient/'\n",
    "no_of_test_patients=math.floor(patients_array.size*0.2) \n",
    "images_data = []\n",
    "models = []\n",
    "\n",
    "df=my_data\n",
    "data_array=df.to_numpy()\n",
    "for i in data_array:\n",
    "    img = cv2.imread(images_path + i[0] + '.' + i[2], cv2.IMREAD_GRAYSCALE)\n",
    "    img=  cv2.equalizeHist(img)\n",
    "    img = cv2.resize(img, (IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "    img_1d = img.reshape(224 * 224)\n",
    "    images_data.append(img_1d)\n",
    "\n",
    "X=np.asarray(images_data)\n",
    "y = np.asarray(my_data['Label'])\n",
    "print(Counter(y))\n",
    "scaler = StandardScaler()\n",
    "# Fit on training set only\n",
    "scaler.fit(X)\n",
    "# Apply transform on both training and test set\n",
    "\n",
    "X = scaler.transform(X)\n",
    "pca = PCA(.95)\n",
    "pca.fit(X)\n",
    "X = pca.transform(X)\n",
    "\n",
    "testPatient_indexes= [1,2,12,14,15,22,\n",
    "                      33,34,37,42,43,52,53,\n",
    "                      92,95,96,99,101,102,104,107,110,115,118]\n",
    "#getting frame indexes of each patient\n",
    "frames_index=[]\n",
    "for i in testPatient_indexes:\n",
    "  j=i*5\n",
    "  z=j+5\n",
    "  while j<z:\n",
    "    frames_index.append(j)\n",
    "    j+=1\n",
    "\n",
    "# Adding the frames to X_test\n",
    "X_test=np.take(X,frames_index,axis=0)\n",
    "y_test=np.take(y,frames_index,axis=0)\n",
    "# Removing the frames from X_train\n",
    "X_train=np.delete(X,frames_index,axis=0)\n",
    "y_train=np.delete(y,frames_index,axis=0)\n",
    "\n",
    "\n",
    "print('X_train: '+str(X_train.shape))\n",
    "print('y_train: '+str(y_train.shape))\n",
    "print('X_test: '+ str(X_test.shape))\n",
    "print('y_test: '+ str(y_test.shape))\n",
    "model=LogisticRegression(random_state=42,solver='lbfgs',max_iter=10000)\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "y_pred=model.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred, digits=3))\n",
    "patient_score(y_test,y_pred)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores=cross_val_score(model, X_train, y_train, cv=5)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
