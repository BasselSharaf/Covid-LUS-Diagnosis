{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32105ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#POCOVID-Net model.\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import (\n",
    "    VGG16\n",
    ")\n",
    "from tensorflow.keras.layers import (\n",
    "    AveragePooling2D,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    Input,\n",
    "    BatchNormalization,\n",
    "    ReLU,\n",
    "    LeakyReLU\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0d75bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_layers(model, num_flex_layers: int = 1):\n",
    "    \"\"\"\n",
    "    Receives a model and freezes all layers but the last num_flex_layers ones.\n",
    "    Arguments:\n",
    "        model {tensorflow.python.keras.engine.training.Model} -- model\n",
    "    Keyword Arguments:\n",
    "        num_flex_layers {int} -- [Number of trainable layers] (default: {1})\n",
    "    Returns:\n",
    "        Model -- updated model\n",
    "    \"\"\"\n",
    "    num_layers = len(model.layers)\n",
    "    for ind, layer in enumerate(model.layers):\n",
    "        if ind < num_layers - num_flex_layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "536851a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(\n",
    "    input_size: tuple = (224, 224, 3),\n",
    "    hidden_size: int = 64,\n",
    "    dropout: float = 0.5,\n",
    "    num_classes: int = 3,\n",
    "    trainable_layers: int = 1,\n",
    "    log_softmax: bool = True,\n",
    "    mc_dropout: bool = False,\n",
    "    **kwargs\n",
    "):\n",
    "    act_fn = tf.nn.softmax if not log_softmax else tf.nn.log_softmax\n",
    "\n",
    "    # load the VGG16 network, ensuring the head FC layer sets are left off\n",
    "    baseModel = VGG16(\n",
    "        weights=\"imagenet\",\n",
    "        include_top=False,\n",
    "        input_tensor=Input(shape=input_size)\n",
    "    )\n",
    "    # construct the head of the model that will be placed on top of the\n",
    "    # the base model\n",
    "    headModel = baseModel.output\n",
    "    headModel = AveragePooling2D(pool_size=(4, 4))(headModel)\n",
    "    headModel = Flatten(name=\"flatten\")(headModel)\n",
    "    headModel = Dense(hidden_size)(headModel)\n",
    "    headModel = BatchNormalization()(headModel)\n",
    "    headModel = ReLU()(headModel)\n",
    "    headModel = (\n",
    "        Dropout(dropout)(headModel, training=True)\n",
    "        if mc_dropout else Dropout(dropout)(headModel)\n",
    "    )\n",
    "    headModel = Dense(num_classes, activation=act_fn)(headModel)\n",
    "\n",
    "    # place the head FC model on top of the base model\n",
    "    model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "\n",
    "    model = fix_layers(model, num_flex_layers=trainable_layers + 8)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927e5f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=20,\n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "mcp_save = ModelCheckpoint(\n",
    "    os.path.join(MODEL_DIR, 'best_weights'),\n",
    "    save_best_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "reduce_lr_loss = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.1,\n",
    "    patience=7,\n",
    "    verbose=1,\n",
    "    epsilon=1e-4,\n",
    "    mode='min'\n",
    ")\n",
    "# To show balanced accuracy\n",
    "metrics = Metrics((testX, testY), model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77feb160",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c647d202",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=20\n",
    "LR=1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "307a0f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(learning_rate=LR, decay=LR / EPOCHS)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66409be5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
