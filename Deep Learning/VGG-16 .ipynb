{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4ae7b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "98f8aefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import math\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#POCOVID-Net model.\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import (\n",
    "    VGG16\n",
    ")\n",
    "from tensorflow.keras.layers import (\n",
    "    AveragePooling2D,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    Input,\n",
    "    BatchNormalization,\n",
    "    ReLU,\n",
    "    LeakyReLU\n",
    ")\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten,MaxPooling2D,Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import (\n",
    "    EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "from imblearn.over_sampling import SVMSMOTE\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3adf23b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics(Callback):\n",
    "\n",
    "    def __init__(self, valid_data, model):\n",
    "        super(Metrics, self).__init__()\n",
    "        self.valid_data = valid_data\n",
    "        self._data = []\n",
    "        self.model = model\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # if epoch:\n",
    "        #     for i in range(1):  # len(self.valid_data)):\n",
    "        x_test_batch, y_test_batch = self.valid_data\n",
    "\n",
    "        y_predict = np.asarray(self.model.predict(x_test_batch))\n",
    "\n",
    "        y_val = np.argmax(y_test_batch, axis=1)\n",
    "        y_predict = np.argmax(y_predict, axis=1)\n",
    "        self._data.append(\n",
    "            {\n",
    "                'val_balanced': balanced_accuracy_score(y_val, y_predict),\n",
    "            }\n",
    "        )\n",
    "        print(f'Balanced accuracy is: {self._data[-1]}')\n",
    "        return\n",
    "\n",
    "    def get_data(self):\n",
    "        return self._data\n",
    "\n",
    "def fix_layers(model, num_flex_layers: int = 1):\n",
    "    \"\"\"\n",
    "    Receives a model and freezes all layers but the last num_flex_layers ones.\n",
    "    Arguments:\n",
    "        model {tensorflow.python.keras.engine.training.Model} -- model\n",
    "    Keyword Arguments:\n",
    "        num_flex_layers {int} -- [Number of trainable layers] (default: {1})\n",
    "    Returns:\n",
    "        Model -- updated model\n",
    "    \"\"\"\n",
    "    num_layers = len(model.layers)\n",
    "    for ind, layer in enumerate(model.layers):\n",
    "        if ind < num_layers - num_flex_layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    return model\n",
    "def get_model(\n",
    "    input_size: tuple = (224, 224, 3),\n",
    "    hidden_size: int = 64,\n",
    "    dropout: float = 0.5,\n",
    "    num_classes: int = 3,\n",
    "    trainable_layers: int = 1,\n",
    "    log_softmax: bool = True,\n",
    "    mc_dropout: bool = False,\n",
    "    **kwargs\n",
    "):\n",
    "    act_fn = tf.nn.softmax if not log_softmax else tf.nn.log_softmax\n",
    "\n",
    "    # load the VGG16 network, ensuring the head FC layer sets are left off\n",
    "    baseModel = VGG16(\n",
    "        weights=\"imagenet\",\n",
    "        include_top=False,\n",
    "        input_tensor=Input(shape=input_size)\n",
    "    )\n",
    "    # construct the head of the model that will be placed on top of the\n",
    "    # the base model\n",
    "    headModel = baseModel.output\n",
    "    headModel = AveragePooling2D(pool_size=(4, 4))(headModel)\n",
    "    headModel = Flatten(name=\"flatten\")(headModel)\n",
    "    headModel = Dense(hidden_size)(headModel)\n",
    "    headModel = BatchNormalization()(headModel)\n",
    "    headModel = ReLU()(headModel)\n",
    "    headModel = (\n",
    "        Dropout(dropout)(headModel, training=True)\n",
    "        if mc_dropout else Dropout(dropout)(headModel)\n",
    "    )\n",
    "    headModel = Dense(num_classes, activation=act_fn)(headModel)\n",
    "\n",
    "    # place the head FC model on top of the base model\n",
    "    model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "\n",
    "    model = fix_layers(model, num_flex_layers=trainable_layers + 8)\n",
    "\n",
    "    return model\n",
    "\n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "    # plot loss\n",
    "    pyplot.subplot(211)\n",
    "    pyplot.title('Cross Entropy Loss')\n",
    "    pyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "    pyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "    # plot accuracy\n",
    "    pyplot.subplot(212)\n",
    "    pyplot.title('Classification Accuracy')\n",
    "    pyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
    "    pyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
    "    # save plot to file\n",
    "    filename = sys.argv[0].split('/')[-1]\n",
    "    pyplot.savefig('' + '_plot.png')\n",
    "    pyplot.close()\n",
    "\n",
    "# run the test harness for evaluating a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b6c5fff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_WIDTH=224\n",
    "IMAGE_HEIGHT=224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "23a362de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'regular': 280, 'pneumonia': 180, 'covid': 150})\n"
     ]
    }
   ],
   "source": [
    "#Load all patients \n",
    "my_data = pd.read_csv('../data/Five_Frames_Per_patient.csv')\n",
    "patients_data=pd.read_csv('../data/videos_data.csv')\n",
    "data_array = my_data.to_numpy()\n",
    "patients_array=patients_data[\"FileName\"].to_numpy()\n",
    "images_path = '../data/Five_Frames_Per_patient/'\n",
    "no_of_test_patients=math.floor(patients_array.size*0.2) \n",
    "images_data = []\n",
    "models = []\n",
    "\n",
    "df=my_data\n",
    "data_array=df.to_numpy()\n",
    "for i in data_array:\n",
    "    img = cv2.imread(images_path + i[0] + '.' + i[2])\n",
    "    img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "    img_2d = img.reshape(IMAGE_WIDTH ,IMAGE_HEIGHT,3)\n",
    "    images_data.append(img_2d)\n",
    "\n",
    "X=np.asarray(images_data)\n",
    "y = np.asarray(my_data['Label'])\n",
    "print(Counter(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "18a3f119",
   "metadata": {},
   "outputs": [],
   "source": [
    "testPatient_indexes= [1,2,15,16,21,22,\n",
    "                      33,34,42,43,52,53,63,\n",
    "                      92,95,96,99,101,102,105,110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4d960910",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting frame indexes of each patient\n",
    "frames_index=[]\n",
    "for i in testPatient_indexes:\n",
    "  j=i*5\n",
    "  z=j+5\n",
    "  while j<z:\n",
    "    frames_index.append(j)\n",
    "    j+=1\n",
    "\n",
    "    \n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=56)\n",
    "'''\n",
    "# Adding the frames to X_test\n",
    "X_test=np.take(X,frames_index,axis=0)\n",
    "y_test=np.take(y,frames_index,axis=0)\n",
    "# Removing the frames from X_train\n",
    "X_train=np.delete(X,frames_index,axis=0)\n",
    "y_train=np.delete(y,frames_index,axis=0)\n",
    "'''\n",
    "# Scale the pixels\n",
    "X_train=X_train/255.0\n",
    "X_test=X_test/255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4752071b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'regular': 222, 'pneumonia': 143, 'covid': 123})\n"
     ]
    }
   ],
   "source": [
    "#Applying \n",
    "\n",
    "counter=Counter(y_train)\n",
    "print(counter)\n",
    "number = preprocessing.LabelEncoder()\n",
    "y_train=number.fit_transform(y_train)\n",
    "y_train=to_categorical(y_train,3)\n",
    "\n",
    "y_test=number.fit_transform(y_test)\n",
    "y_test=to_categorical(y_test,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "33a15d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (488, 224, 224, 3)\n",
      "y_train: (488, 3)\n",
      "X_test: (122, 224, 224, 3)\n",
      "y_test: (122, 3)\n"
     ]
    }
   ],
   "source": [
    "print('X_train: '+str(X_train.shape))\n",
    "print('y_train: '+str(y_train.shape))\n",
    "print('X_test: '+ str(X_test.shape))\n",
    "print('y_test: '+ str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0245279c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainAug = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    fill_mode='nearest',\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ")\n",
    "earlyStopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=20,\n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "mcp_save = ModelCheckpoint(\n",
    "    os.path.join('', \"Conv2d-VGG-16\"),\n",
    "    save_best_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "reduce_lr_loss = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.1,\n",
    "    patience=7,\n",
    "    verbose=1,\n",
    "    mine_delta=1e-4,\n",
    "    mode='min'\n",
    ")\n",
    "# To show balanced accuracy\n",
    "metrics = Metrics((X_test, y_test), model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c73c0eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=get_model()\n",
    "EPOCHS=20\n",
    "LR=1e-4\n",
    "BATCH_SIZE=16\n",
    "opt = Adam(learning_rate=LR, decay=LR / EPOCHS)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a34f8182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has 14747971 parameters\n",
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_8 (Average (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "re_lu_8 (ReLU)               (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 14,747,971\n",
      "Trainable params: 14,747,843\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "Model summary None\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=loss, optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "print(f'Model has {model.count_params()} parameters')\n",
    "print(f'Model summary {model.summary()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e586e801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 15s 401ms/step - loss: 1.0432 - accuracy: 0.1970 - val_loss: 1.0469 - val_accuracy: 0.2213\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.22131, saving model to Conv2d-VGG-16\n",
      "INFO:tensorflow:Assets written to: Conv2d-VGG-16\\assets\n",
      "Balanced accuracy is: {'val_balanced': 0.3333333333333333}\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 11s 348ms/step - loss: 0.8780 - accuracy: 0.1165 - val_loss: 1.6078 - val_accuracy: 0.2213\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.22131\n",
      "Balanced accuracy is: {'val_balanced': 0.3333333333333333}\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 11s 350ms/step - loss: 0.8133 - accuracy: 0.1102 - val_loss: 3.2692 - val_accuracy: 0.4754\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.22131 to 0.47541, saving model to Conv2d-VGG-16\n",
      "INFO:tensorflow:Assets written to: Conv2d-VGG-16\\assets\n",
      "Balanced accuracy is: {'val_balanced': 0.3333333333333333}\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 11s 350ms/step - loss: 0.7540 - accuracy: 0.0805 - val_loss: 2.1020 - val_accuracy: 0.4016\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.47541\n",
      "Balanced accuracy is: {'val_balanced': 0.28160919540229884}\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 11s 349ms/step - loss: 0.7100 - accuracy: 0.0636 - val_loss: 2.1244 - val_accuracy: 0.4754\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.47541\n",
      "Balanced accuracy is: {'val_balanced': 0.3333333333333333}\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 11s 350ms/step - loss: 0.7309 - accuracy: 0.0551 - val_loss: 2.4868 - val_accuracy: 0.2623\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.47541\n",
      "Balanced accuracy is: {'val_balanced': 0.1839080459770115}\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 11s 350ms/step - loss: 0.7488 - accuracy: 0.0678 - val_loss: 4.4516 - val_accuracy: 0.4754\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.47541\n",
      "Balanced accuracy is: {'val_balanced': 0.3333333333333333}\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 11s 352ms/step - loss: 0.6944 - accuracy: 0.0678 - val_loss: 1.0427 - val_accuracy: 0.0820\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.47541\n",
      "Balanced accuracy is: {'val_balanced': 0.10366113239676457}\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 11s 351ms/step - loss: 0.5853 - accuracy: 0.0297 - val_loss: 2.1124 - val_accuracy: 0.4098\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.47541\n",
      "Balanced accuracy is: {'val_balanced': 0.28735632183908044}\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 11s 351ms/step - loss: 0.6102 - accuracy: 0.0424 - val_loss: 2.4653 - val_accuracy: 0.3115\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.47541\n",
      "Balanced accuracy is: {'val_balanced': 0.21839080459770113}\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 11s 350ms/step - loss: 0.5792 - accuracy: 0.0297 - val_loss: 3.3641 - val_accuracy: 0.3033\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.47541\n",
      "Balanced accuracy is: {'val_balanced': 0.3333333333333333}\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 11s 351ms/step - loss: 0.5853 - accuracy: 0.0403 - val_loss: 1.5596 - val_accuracy: 0.0984\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.47541\n",
      "Balanced accuracy is: {'val_balanced': 0.06896551724137931}\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 11s 352ms/step - loss: 0.5483 - accuracy: 0.0339 - val_loss: 1.6966 - val_accuracy: 0.1885\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.47541\n",
      "Balanced accuracy is: {'val_balanced': 0.13218390804597702}\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 11s 351ms/step - loss: 0.5619 - accuracy: 0.0254 - val_loss: 0.9578 - val_accuracy: 0.0738\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.47541\n",
      "Balanced accuracy is: {'val_balanced': 0.1111111111111111}\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 11s 351ms/step - loss: 0.5964 - accuracy: 0.0487 - val_loss: 1.7393 - val_accuracy: 0.1721\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.47541\n",
      "Balanced accuracy is: {'val_balanced': 0.25925925925925924}\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 11s 351ms/step - loss: 0.6074 - accuracy: 0.0403 - val_loss: 2.3867 - val_accuracy: 0.3033\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.47541\n",
      "Balanced accuracy is: {'val_balanced': 0.3333333333333333}\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 11s 351ms/step - loss: 0.5997 - accuracy: 0.0403 - val_loss: 1.4289 - val_accuracy: 0.0656\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.47541\n",
      "Balanced accuracy is: {'val_balanced': 0.07237122179650915}\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 11s 356ms/step - loss: 0.5709 - accuracy: 0.0297 - val_loss: 1.4524 - val_accuracy: 0.0738\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.47541\n",
      "Balanced accuracy is: {'val_balanced': 0.10451255853554703}\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 11s 351ms/step - loss: 0.4818 - accuracy: 0.0169 - val_loss: 0.6508 - val_accuracy: 0.0738\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.47541\n",
      "Balanced accuracy is: {'val_balanced': 0.05172413793103448}\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 11s 351ms/step - loss: 0.5019 - accuracy: 0.0254 - val_loss: 0.5604 - val_accuracy: 0.0246\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.47541\n",
      "Balanced accuracy is: {'val_balanced': 0.02376514445479963}\n"
     ]
    }
   ],
   "source": [
    "H = model.fit(\n",
    "    trainAug.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "    steps_per_epoch=len(X_train) // BATCH_SIZE,\n",
    "    validation_data=(X_test, y_test),\n",
    "    validation_steps=len(X_test) // BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[earlyStopping, mcp_save, reduce_lr_loss,metrics]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d92fb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3622b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
