{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1e54908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data...\n",
      "Random seeds are: [777, 258, 271, 661, 978, 930, 576]\n",
      "--------------------------------- Iteration 0--------------------------------- \n",
      "\n",
      "Equalizing Data...\n",
      "50176\n",
      "Normalizing and applying PCA...\n",
      "75\n",
      "Training Models...\n",
      "getting predictions of each model...\n",
      "[[34  0  1]\n",
      " [ 0 24  1]\n",
      " [ 0  2 60]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       covid      1.000     0.971     0.986        35\n",
      "   pneumonia      0.923     0.960     0.941        25\n",
      "     regular      0.968     0.968     0.968        62\n",
      "\n",
      "    accuracy                          0.967       122\n",
      "   macro avg      0.964     0.966     0.965       122\n",
      "weighted avg      0.968     0.967     0.967       122\n",
      "\n",
      "--------------------------------- Iteration 1--------------------------------- \n",
      "\n",
      "Equalizing Data...\n",
      "50176\n",
      "Normalizing and applying PCA...\n",
      "79\n",
      "Training Models...\n",
      "getting predictions of each model...\n",
      "[[26  0  0]\n",
      " [ 0 29  1]\n",
      " [ 0  4 62]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       covid      1.000     1.000     1.000        26\n",
      "   pneumonia      0.879     0.967     0.921        30\n",
      "     regular      0.984     0.939     0.961        66\n",
      "\n",
      "    accuracy                          0.959       122\n",
      "   macro avg      0.954     0.969     0.961       122\n",
      "weighted avg      0.962     0.959     0.960       122\n",
      "\n",
      "--------------------------------- Iteration 2--------------------------------- \n",
      "\n",
      "Equalizing Data...\n",
      "50176\n",
      "Normalizing and applying PCA...\n",
      "75\n",
      "Training Models...\n",
      "getting predictions of each model...\n",
      "[[35  0  0]\n",
      " [ 0 31  0]\n",
      " [ 0  0 56]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       covid      1.000     1.000     1.000        35\n",
      "   pneumonia      1.000     1.000     1.000        31\n",
      "     regular      1.000     1.000     1.000        56\n",
      "\n",
      "    accuracy                          1.000       122\n",
      "   macro avg      1.000     1.000     1.000       122\n",
      "weighted avg      1.000     1.000     1.000       122\n",
      "\n",
      "--------------------------------- Iteration 3--------------------------------- \n",
      "\n",
      "Equalizing Data...\n",
      "50176\n",
      "Normalizing and applying PCA...\n",
      "81\n",
      "Training Models...\n",
      "getting predictions of each model...\n",
      "[[20  0  1]\n",
      " [ 0 40  2]\n",
      " [ 0  0 59]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       covid      1.000     0.952     0.976        21\n",
      "   pneumonia      1.000     0.952     0.976        42\n",
      "     regular      0.952     1.000     0.975        59\n",
      "\n",
      "    accuracy                          0.975       122\n",
      "   macro avg      0.984     0.968     0.975       122\n",
      "weighted avg      0.977     0.975     0.975       122\n",
      "\n",
      "--------------------------------- Iteration 4--------------------------------- \n",
      "\n",
      "Equalizing Data...\n",
      "50176\n",
      "Normalizing and applying PCA...\n",
      "77\n",
      "Training Models...\n",
      "getting predictions of each model...\n",
      "[[35  0  0]\n",
      " [ 0 35  0]\n",
      " [ 1  2 49]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       covid      0.972     1.000     0.986        35\n",
      "   pneumonia      0.946     1.000     0.972        35\n",
      "     regular      1.000     0.942     0.970        52\n",
      "\n",
      "    accuracy                          0.975       122\n",
      "   macro avg      0.973     0.981     0.976       122\n",
      "weighted avg      0.977     0.975     0.975       122\n",
      "\n",
      "--------------------------------- Iteration 5--------------------------------- \n",
      "\n",
      "Equalizing Data...\n",
      "50176\n",
      "Normalizing and applying PCA...\n",
      "79\n",
      "Training Models...\n",
      "getting predictions of each model...\n",
      "[[29  0  0]\n",
      " [ 0 30  1]\n",
      " [ 0  0 62]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       covid      1.000     1.000     1.000        29\n",
      "   pneumonia      1.000     0.968     0.984        31\n",
      "     regular      0.984     1.000     0.992        62\n",
      "\n",
      "    accuracy                          0.992       122\n",
      "   macro avg      0.995     0.989     0.992       122\n",
      "weighted avg      0.992     0.992     0.992       122\n",
      "\n",
      "--------------------------------- Iteration 6--------------------------------- \n",
      "\n",
      "Equalizing Data...\n",
      "50176\n",
      "Normalizing and applying PCA...\n",
      "78\n",
      "Training Models...\n",
      "getting predictions of each model...\n",
      "[[34  0  1]\n",
      " [ 0 32  1]\n",
      " [ 0  1 53]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       covid      1.000     0.971     0.986        35\n",
      "   pneumonia      0.970     0.970     0.970        33\n",
      "     regular      0.964     0.981     0.972        54\n",
      "\n",
      "    accuracy                          0.975       122\n",
      "   macro avg      0.978     0.974     0.976       122\n",
      "weighted avg      0.976     0.975     0.975       122\n",
      "\n",
      "Average f1 micro of all iterations is: 0.977751756440281\n",
      "Saving models....\n",
      "All Done :)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from mostCommon import most_common\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "my_data = pd.read_csv('../data/Five_Frames_Per_patient.csv')\n",
    "data_array = my_data.to_numpy()\n",
    "images_path = '../data/Five_Frames_Per_patient/'\n",
    "images_data = []\n",
    "models = []\n",
    "\n",
    "print('processing data...')\n",
    "for i in data_array:\n",
    "    img = cv2.imread(images_path + i[0] + '.' + i[2], cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.equalizeHist(img)\n",
    "    img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_AREA)\n",
    "    img_1d = img.reshape(224 * 224)\n",
    "    images_data.append(img_1d)\n",
    "\n",
    "r = []\n",
    "conf_matricies = []\n",
    "f1_reports = []\n",
    "f1_micro = []\n",
    "for i in range(7):\n",
    "    r.append(random.randint(0, 1000))\n",
    "print('Random seeds are: '+str(r))\n",
    "\n",
    "number_of_models = 11\n",
    "X = np.asarray(images_data)\n",
    "y = np.asarray(my_data['Label'])\n",
    "\n",
    "for k in range(len(r)):\n",
    "    print('--------------------------------- Iteration ' + str(k) + '--------------------------------- \\n')\n",
    "    Xandy = []\n",
    "    models = []\n",
    "    # creating models\n",
    "    for i in range(number_of_models):\n",
    "        models.append(make_pipeline(StandardScaler(), SVC(gamma='auto', random_state=r[k])))\n",
    "\n",
    "    # Creating array test splits for models\n",
    "    # X_train, X_test, y_train, y_test\n",
    "    for i in range(number_of_models):\n",
    "        x = train_test_split(X, y, test_size=0.2, random_state=r[k])\n",
    "        Xandy.append(x)\n",
    "\n",
    "    print('Equalizing Data...')\n",
    "    for i in range(number_of_models):\n",
    "        x = Xandy[i][0]\n",
    "        y1 = Xandy[i][2]\n",
    "        cov = np.count_nonzero(y1 == 'covid')\n",
    "        pneu = np.count_nonzero(y1 == 'pneumonia')\n",
    "        reg = np.count_nonzero(y1 == 'regular')\n",
    "        # deleting random pneumonia elements from each model set\n",
    "        while cov != pneu:\n",
    "            index = random.randint(0, len(x) - 1)\n",
    "            if y1[index] == 'pneumonia':\n",
    "                x = np.delete(x, index, 0)\n",
    "                y1 = np.delete(y1, index, 0)\n",
    "                pneu -= 1\n",
    "        # deleting random regular elements from each model set\n",
    "        while cov != reg:\n",
    "            index = random.randint(0, len(x) - 1)\n",
    "            if y1[index] == 'regular':\n",
    "                x = np.delete(x, index, 0)\n",
    "                y1 = np.delete(y1, index, 0)\n",
    "                reg -= 1\n",
    "        Xandy[i][0] = x\n",
    "        Xandy[i][2] = y1\n",
    "    print(len(Xandy[0][0][0]))\n",
    "    print('Normalizing and applying PCA...')\n",
    "    for i in range(number_of_models):\n",
    "        scaler = StandardScaler()\n",
    "        # Fit on training set only\n",
    "        scaler.fit(Xandy[i][0])\n",
    "\n",
    "        # Apply transform on both training and test set\n",
    "        Xandy[i][0] = scaler.transform(Xandy[i][0])\n",
    "        Xandy[i][1] = scaler.transform(Xandy[i][1])\n",
    "    for i in range(number_of_models):\n",
    "        pca = PCA(.95)\n",
    "        pca.fit(Xandy[i][0])\n",
    "        Xandy[i][0] = pca.transform(Xandy[i][0])\n",
    "        Xandy[i][1] = pca.transform(Xandy[i][1])\n",
    "    print(len(Xandy[0][0][0]))\n",
    "    print('Training Models...')\n",
    "    for i in range(number_of_models):\n",
    "        models[i].fit(Xandy[i][0], Xandy[i][2])\n",
    "\n",
    "    print('getting predictions of each model...')\n",
    "    predicted = []\n",
    "    for i in range(number_of_models):\n",
    "        predicted.append(models[i].predict(Xandy[i][1]))\n",
    "\n",
    "    voted_prediction = []\n",
    "    for i in range(len(predicted[0])):\n",
    "        voting = []\n",
    "        for j in range(len(predicted)):\n",
    "            voting.append(predicted[j][i])\n",
    "        voted_prediction.append(most_common(voting))\n",
    "    conf_matrix = confusion_matrix(Xandy[0][3], voted_prediction)\n",
    "    print(conf_matrix)\n",
    "    conf_matricies.append(conf_matrix)\n",
    "\n",
    "    classification_report = metrics.classification_report(Xandy[0][3], voted_prediction, digits=3)\n",
    "    print(classification_report)\n",
    "    f1_reports.append(classification_report)\n",
    "    f1_micro.append(f1_score(Xandy[0][3], voted_prediction, average='micro'))\n",
    "\n",
    "print('Average f1 micro of all iterations is: ' + str(sum(f1_micro) / len(f1_micro)))\n",
    "\n",
    "print('Saving models....')\n",
    "np.save('models', models)\n",
    "print('All Done :)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac693a89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
