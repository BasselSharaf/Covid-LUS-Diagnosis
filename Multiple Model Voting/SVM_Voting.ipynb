{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2c291ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data...\n",
      "Random seeds are: \n",
      "[29, 21, 80, 41, 21]\n",
      "--------------------------------- Iteration 0--------------------------------- \n",
      "\n",
      "Equalizing Data...\n",
      "Training Models...\n",
      "getting predictions of each model...\n",
      "\n",
      "[[27  0  0]\n",
      " [ 0 31  2]\n",
      " [ 4  1 57]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       covid      0.871     1.000     0.931        27\n",
      "   pneumonia      0.969     0.939     0.954        33\n",
      "     regular      0.966     0.919     0.942        62\n",
      "\n",
      "    accuracy                          0.943       122\n",
      "   macro avg      0.935     0.953     0.942       122\n",
      "weighted avg      0.946     0.943     0.943       122\n",
      "\n",
      "--------------------------------- Iteration 1--------------------------------- \n",
      "\n",
      "Equalizing Data...\n",
      "Training Models...\n",
      "getting predictions of each model...\n",
      "\n",
      "[[31  0  1]\n",
      " [ 0 32  0]\n",
      " [ 0  2 56]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       covid      1.000     0.969     0.984        32\n",
      "   pneumonia      0.941     1.000     0.970        32\n",
      "     regular      0.982     0.966     0.974        58\n",
      "\n",
      "    accuracy                          0.975       122\n",
      "   macro avg      0.975     0.978     0.976       122\n",
      "weighted avg      0.976     0.975     0.975       122\n",
      "\n",
      "--------------------------------- Iteration 2--------------------------------- \n",
      "\n",
      "Equalizing Data...\n",
      "Training Models...\n",
      "getting predictions of each model...\n",
      "\n",
      "[[33  4  0]\n",
      " [ 0 32  2]\n",
      " [ 0  2 49]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       covid      1.000     0.892     0.943        37\n",
      "   pneumonia      0.842     0.941     0.889        34\n",
      "     regular      0.961     0.961     0.961        51\n",
      "\n",
      "    accuracy                          0.934       122\n",
      "   macro avg      0.934     0.931     0.931       122\n",
      "weighted avg      0.940     0.934     0.935       122\n",
      "\n",
      "--------------------------------- Iteration 3--------------------------------- \n",
      "\n",
      "Equalizing Data...\n",
      "Training Models...\n",
      "getting predictions of each model...\n",
      "\n",
      "[[21  2  0]\n",
      " [ 0 33  2]\n",
      " [ 6  1 57]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       covid      0.778     0.913     0.840        23\n",
      "   pneumonia      0.917     0.943     0.930        35\n",
      "     regular      0.966     0.891     0.927        64\n",
      "\n",
      "    accuracy                          0.910       122\n",
      "   macro avg      0.887     0.916     0.899       122\n",
      "weighted avg      0.916     0.910     0.911       122\n",
      "\n",
      "--------------------------------- Iteration 4--------------------------------- \n",
      "\n",
      "Equalizing Data...\n",
      "Training Models...\n",
      "getting predictions of each model...\n",
      "\n",
      "[[31  0  1]\n",
      " [ 0 32  0]\n",
      " [ 1  1 56]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       covid      0.969     0.969     0.969        32\n",
      "   pneumonia      0.970     1.000     0.985        32\n",
      "     regular      0.982     0.966     0.974        58\n",
      "\n",
      "    accuracy                          0.975       122\n",
      "   macro avg      0.974     0.978     0.976       122\n",
      "weighted avg      0.976     0.975     0.975       122\n",
      "\n",
      "Average f1 micro of all iterations is: 0.9475409836065575\n",
      "Saving models....\n",
      "All Done :)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from mostCommon import most_common\n",
    "from sklearn.metrics import f1_score\n",
    "import pickle\n",
    "\n",
    "my_data = pd.read_csv('../data/Five_Frames_Per_patient.csv')\n",
    "data_array = my_data.to_numpy()\n",
    "images_path = '../data/Five_Frames_Per_patient/'\n",
    "images_data = []\n",
    "models = []\n",
    "\n",
    "print('processing data...')\n",
    "for i in data_array:\n",
    "    img = cv2.imread(images_path + i[0] + '.' + i[2], cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.equalizeHist(img)\n",
    "    img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_AREA)\n",
    "    img_1d = img.reshape(224 * 224)\n",
    "    images_data.append(img_1d)\n",
    "\n",
    "r = []\n",
    "conf_matricies = []\n",
    "f1_reports = []\n",
    "f1_micro = []\n",
    "for i in range(5):\n",
    "    r.append(random.randint(0, 100))\n",
    "print('Random seeds are: ')\n",
    "print(r)\n",
    "\n",
    "\n",
    "number_of_models = 11\n",
    "X = np.asarray(images_data)\n",
    "y = np.asarray(my_data['Label'])\n",
    "\n",
    "for k in range(len(r)):\n",
    "    print('--------------------------------- Iteration '+str(k)+'--------------------------------- \\n')\n",
    "    Xandy = []\n",
    "    models = []\n",
    "    # creating models\n",
    "    for i in range(number_of_models):\n",
    "        models.append(make_pipeline(StandardScaler(), SVC(gamma='auto', random_state=r[k])))\n",
    "\n",
    "    # Creating array test splits for models\n",
    "    # X_train, X_test, y_train, y_test\n",
    "    for i in range(number_of_models):\n",
    "        x = train_test_split(X, y, test_size=0.2, random_state=r[k])\n",
    "        Xandy.append(x)\n",
    "\n",
    "    print('Equalizing Data...')\n",
    "    for i in range(number_of_models):\n",
    "        x = Xandy[i][0]\n",
    "        y1 = Xandy[i][2]\n",
    "        cov = np.count_nonzero(y1 == 'covid')\n",
    "        pneu = np.count_nonzero(y1 == 'pneumonia')\n",
    "        reg = np.count_nonzero(y1 == 'regular')\n",
    "        # deleting random pneumonia elements from each model set\n",
    "        while cov != pneu:\n",
    "            index = random.randint(0, len(x) - 1)\n",
    "            if y1[index] == 'pneumonia':\n",
    "                x = np.delete(x, index, 0)\n",
    "                y1 = np.delete(y1, index, 0)\n",
    "                pneu -= 1\n",
    "        # deleting random regular elements from each model set\n",
    "        while cov != reg:\n",
    "            index = random.randint(0, len(x) - 1)\n",
    "            if y1[index] == 'regular':\n",
    "                x = np.delete(x, index, 0)\n",
    "                y1 = np.delete(y1, index, 0)\n",
    "                reg -= 1\n",
    "        Xandy[i][0] = x\n",
    "        Xandy[i][2] = y1\n",
    "\n",
    "    print('Training Models...')\n",
    "    for i in range(number_of_models):\n",
    "        models[i].fit(Xandy[i][0], Xandy[i][2])\n",
    "\n",
    "    print('getting predictions of each model...')\n",
    "    predicted = []\n",
    "    for i in range(number_of_models):\n",
    "        predicted.append(models[i].predict(Xandy[i][1]))\n",
    "\n",
    "    voted_prediction = []\n",
    "    for i in range(len(predicted[0])):\n",
    "        voting = []\n",
    "        for j in range(len(predicted)):\n",
    "            voting.append(predicted[j][i])\n",
    "        voted_prediction.append(most_common(voting))\n",
    "\n",
    "    print('')\n",
    "    conf_matrix = confusion_matrix(Xandy[0][3], voted_prediction)\n",
    "    print(conf_matrix)\n",
    "    conf_matricies.append(conf_matrix)\n",
    "\n",
    "    classification_report = metrics.classification_report(Xandy[0][3], voted_prediction, digits=3)\n",
    "    print(classification_report)\n",
    "    f1_reports.append(classification_report)\n",
    "    f1_micro.append(f1_score(Xandy[0][3], voted_prediction, average='micro'))\n",
    "\n",
    "\n",
    "print('Average f1 micro of all iterations is: '+str(sum(f1_micro)/len(f1_micro)))\n",
    "\n",
    "print('Saving models....')\n",
    "np.save('models', models)\n",
    "print('All Done :)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c92198e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
